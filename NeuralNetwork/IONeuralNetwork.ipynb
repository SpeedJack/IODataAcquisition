{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IONeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7L5rGCIs3sc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b61bb416-95bb-4c58-a1b9-389f14c64082"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product, chain, combinations\n",
        "from scipy import stats\n",
        "from IPython.display import display, HTML\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_rows',70)\n",
        "display(HTML(\"<style>div.output_scroll { height: auto; max-height: 48em; }</style>\"))\n",
        "\n",
        "def parse_if_number(s):\n",
        "    try: return float(s)\n",
        "    except: return True if s==\"true\" else False if s==\"false\" else s if s else None\n",
        "\n",
        "def parse_ndarray(s):\n",
        "    return np.fromstring(s, sep=' ') if s else None\n",
        "\n",
        "def get_file_name(name):\n",
        "    return name.replace(':', '-')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>div.output_scroll { height: auto; max-height: 48em; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqjESA2vvfVX"
      },
      "source": [
        "inputFile = 'collected-data.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "LY4PBKuhviNX",
        "outputId": "ded4456d-2221-468a-9115-77b5d43d95a1"
      },
      "source": [
        "df = pd.read_csv(inputFile)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sensor_type</th>\n",
              "      <th>sensor_name</th>\n",
              "      <th>value</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1620723880333</td>\n",
              "      <td>-1</td>\n",
              "      <td>INDOOR</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1620723880364</td>\n",
              "      <td>-1</td>\n",
              "      <td>MONITORING</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1620723873432</td>\n",
              "      <td>5</td>\n",
              "      <td>TMD3725_Light Ambient Light Sensor Non-wakeup</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1620723873265</td>\n",
              "      <td>8</td>\n",
              "      <td>TMD3725_Proximity Proximity Sensor Wakeup</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1620723882262</td>\n",
              "      <td>-1</td>\n",
              "      <td>GPS_SATELLITES</td>\n",
              "      <td>17.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2403</th>\n",
              "      <td>1620733476294</td>\n",
              "      <td>5</td>\n",
              "      <td>TMD3725_Light Ambient Light Sensor Non-wakeup</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2404</th>\n",
              "      <td>1620733477129</td>\n",
              "      <td>8</td>\n",
              "      <td>TMD3725_Proximity Proximity Sensor Wakeup</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2405</th>\n",
              "      <td>1620733477434</td>\n",
              "      <td>5</td>\n",
              "      <td>TMD3725_Light Ambient Light Sensor Non-wakeup</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406</th>\n",
              "      <td>1620733480731</td>\n",
              "      <td>5</td>\n",
              "      <td>TMD3725_Light Ambient Light Sensor Non-wakeup</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2407</th>\n",
              "      <td>1620733488783</td>\n",
              "      <td>-1</td>\n",
              "      <td>MONITORING</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2408 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          timestamp  sensor_type  ... value  accuracy\n",
              "0     1620723880333           -1  ...   1.0       NaN\n",
              "1     1620723880364           -1  ...   1.0       NaN\n",
              "2     1620723873432            5  ...  15.0       3.0\n",
              "3     1620723873265            8  ...   5.0       3.0\n",
              "4     1620723882262           -1  ...  17.0       NaN\n",
              "...             ...          ...  ...   ...       ...\n",
              "2403  1620733476294            5  ...   8.0       3.0\n",
              "2404  1620733477129            8  ...   5.0       3.0\n",
              "2405  1620733477434            5  ...   2.0       3.0\n",
              "2406  1620733480731            5  ...   2.0       3.0\n",
              "2407  1620733488783           -1  ...   0.0       NaN\n",
              "\n",
              "[2408 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXSOeqYI7TJv"
      },
      "source": [
        "sensor_type_dict = {\n",
        "    'MONITORING':-1,\n",
        "    'INDOOR':-2,\n",
        "    'GPS_SATELLITES':-3,\n",
        "    'GPS_FIX_SATELLITES':-4,\n",
        "    'GPS_FIX':-5,\n",
        "    'DETECTED_ACTIVITY':-6,\n",
        "    'WIFI_ACCESS_POINTS':-7,\n",
        "    'BLUETOOTH_DEVICES':-8\n",
        "}\n",
        "\n",
        "for index,row in df.iterrows():\n",
        "    if  df.loc[index,'sensor_type'] == -1:\n",
        "        df.loc[index,'sensor_type'] = sensor_type_dict[ row['sensor_name']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "raYmLR2h7TJy",
        "outputId": "3f6d3a13-1786-42f2-8057-39260b7038aa"
      },
      "source": [
        "df_wide = df.pivot_table(index=['timestamp'], columns='sensor_name', values='value')\n",
        "\n",
        "\n",
        "last_seen_values = {}\n",
        "sensor_types = df['sensor_name'].unique()\n",
        "for sensor_type in sensor_types:\n",
        "    last_seen_values[sensor_type] = float('nan')\n",
        "\n",
        "for index,row in df_wide.iterrows():\n",
        "    if row['MONITORING'] == 0:\n",
        "        for sensor_type in sensor_types:\n",
        "            last_seen_values[sensor_type] = float('nan')\n",
        "    else:        \n",
        "        for sensor_type in sensor_types:\n",
        "            if math.isnan(row[sensor_type]):\n",
        "                row[sensor_type] = last_seen_values[sensor_type]\n",
        "            last_seen_values[sensor_type] = row[sensor_type] \n",
        "\n",
        "for index,row in df_wide.iterrows():\n",
        "    containsNaN = 0.0\n",
        "    for sensor_type in sensor_types:\n",
        "        if math.isnan(row[sensor_type]):\n",
        "            containsNaN = 1.0\n",
        "            break\n",
        "    df_wide.loc[index,'containsNaN'] = containsNaN\n",
        "\n",
        "df_wide = df_wide[(df_wide['MONITORING'] == 1.0) & (df_wide['containsNaN'] == 0.0)] \n",
        "del df_wide['containsNaN']\n",
        "\n",
        "proximity_name = \"\"\n",
        "light_name = \"\"\n",
        "for sensor_type in sensor_types:\n",
        "    if 'proximity' in sensor_type.lower():\n",
        "        proximity_name = sensor_type\n",
        "        break\n",
        "    if 'light' in sensor_type.lower():\n",
        "        light_name = sensor_type\n",
        "        \n",
        "df_wide.loc[(df_wide[proximity_name] != 0.0),proximity_name] = 1\n",
        "\n",
        "Detected_Activity_List = {\n",
        "  0.0 : \"IN_VEHICLE\",\n",
        "  1.0 : \"ON_BICYCLE\",\n",
        "  2.0 : \"ON_FOOT\",\n",
        "  3.0 : \"STILL\",\n",
        "  4.0 : \"UNKOWN\",\n",
        "  5.0 : \"TILTING\",\n",
        "  7.0 : \"WALKING\",\n",
        "  8.0 : \"RUNNING\"\n",
        "}\n",
        "\n",
        "for key in Detected_Activity_List.keys(): \n",
        "  df_wide[Detected_Activity_List[key]] = df_wide['DETECTED_ACTIVITY'] == key\n",
        "\n",
        "df_wide.sort_values(['timestamp'], inplace=True)\n",
        "target = df_wide.loc[:,'INDOOR']\n",
        "del df_wide['INDOOR']\n",
        "del df_wide['GPS_FIX']\n",
        "del df_wide['MONITORING']\n",
        "del df_wide['DETECTED_ACTIVITY']\n",
        "\n",
        "cols = [sensor_type for sensor_type in df_wide.columns.to_list() if sensor_type != proximity_name]\n",
        "cols.append(proximity_name)\n",
        "df_wide = df_wide[cols].replace(True,1.0).replace(False,0.0)\n",
        "df_wide.to_csv('preprocessed_data.csv')\n",
        "target.to_numpy()\n",
        "df_wide"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>sensor_name</th>\n",
              "      <th>BLUETOOTH_DEVICES</th>\n",
              "      <th>GPS_FIX_SATELLITES</th>\n",
              "      <th>GPS_SATELLITES</th>\n",
              "      <th>TMD3725_Light Ambient Light Sensor Non-wakeup</th>\n",
              "      <th>WIFI_ACCESS_POINTS</th>\n",
              "      <th>IN_VEHICLE</th>\n",
              "      <th>ON_BICYCLE</th>\n",
              "      <th>ON_FOOT</th>\n",
              "      <th>STILL</th>\n",
              "      <th>UNKOWN</th>\n",
              "      <th>TILTING</th>\n",
              "      <th>WALKING</th>\n",
              "      <th>RUNNING</th>\n",
              "      <th>TMD3725_Proximity Proximity Sensor Wakeup</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1620724298381</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620724299464</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620724300115</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620724300588</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620724300600</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620733475300</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620733476294</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620733477129</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620733477434</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620733480731</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2316 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "sensor_name    BLUETOOTH_DEVICES  ...  TMD3725_Proximity Proximity Sensor Wakeup\n",
              "timestamp                         ...                                           \n",
              "1620724298381                1.0  ...                                        0.0\n",
              "1620724299464                1.0  ...                                        0.0\n",
              "1620724300115                1.0  ...                                        1.0\n",
              "1620724300588                1.0  ...                                        1.0\n",
              "1620724300600                2.0  ...                                        1.0\n",
              "...                          ...  ...                                        ...\n",
              "1620733475300                0.0  ...                                        0.0\n",
              "1620733476294                0.0  ...                                        0.0\n",
              "1620733477129                0.0  ...                                        1.0\n",
              "1620733477434                0.0  ...                                        1.0\n",
              "1620733480731                0.0  ...                                        1.0\n",
              "\n",
              "[2316 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSazBHS27TJ2",
        "outputId": "1af5bcfd-f626-4564-f228-00ddf922252a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_wide.to_numpy(), target, test_size=0.33) \n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1551, 14) (765, 14) (1551,) (765,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHkz_y2q7TJ9",
        "outputId": "9f72353a-6dd0-47f6-9026-263d6cc120f0"
      },
      "source": [
        "D = X_train.shape[1]\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.,  0., 17., ...,  0.,  0.,  1.],\n",
              "       [ 2.,  0., 17., ...,  0.,  0.,  1.],\n",
              "       [ 0.,  0., 37., ...,  0.,  0.,  1.],\n",
              "       ...,\n",
              "       [ 1.,  0., 36., ...,  0.,  0.,  1.],\n",
              "       [ 0.,  0., 36., ...,  0.,  0.,  1.],\n",
              "       [ 1.,  0., 36., ...,  0.,  0.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3NSTgbH7TJ_",
        "outputId": "f62c8317-f71d-4856-abf1-de97e2e04898"
      },
      "source": [
        "# Now all the fun Tensorflow stuff\n",
        "# Build the model\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(shape=(D,)),\n",
        "  tf.keras.layers.LayerNormalization(axis=-1),  \n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "numpy_input = K.Input(shape=(10,), name=\"numpy_input\")\n",
        "\n",
        "# Alternatively, you can do:\n",
        "# model = tf.keras.models.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200)\n",
        "\n",
        "\n",
        "# Evaluate the model - evaluate() returns loss and accuracy\n",
        "print(\"Train score:\", model.evaluate(X_train, y_train))\n",
        "print(\"Test score:\", model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "49/49 [==============================] - 1s 7ms/step - loss: 0.6913 - accuracy: 0.5389 - val_loss: 0.6546 - val_accuracy: 0.5908\n",
            "Epoch 2/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.5752 - val_loss: 0.6273 - val_accuracy: 0.6170\n",
            "Epoch 3/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.5994 - val_loss: 0.6010 - val_accuracy: 0.6444\n",
            "Epoch 4/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.6376 - val_loss: 0.5759 - val_accuracy: 0.7059\n",
            "Epoch 5/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.6779 - val_loss: 0.5527 - val_accuracy: 0.7333\n",
            "Epoch 6/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.6983 - val_loss: 0.5306 - val_accuracy: 0.7725\n",
            "Epoch 7/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7841 - val_loss: 0.5097 - val_accuracy: 0.8379\n",
            "Epoch 8/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8228 - val_loss: 0.4911 - val_accuracy: 0.8667\n",
            "Epoch 9/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.8415 - val_loss: 0.4726 - val_accuracy: 0.8693\n",
            "Epoch 10/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8251 - val_loss: 0.4569 - val_accuracy: 0.8758\n",
            "Epoch 11/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.8505 - val_loss: 0.4416 - val_accuracy: 0.8758\n",
            "Epoch 12/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8376 - val_loss: 0.4282 - val_accuracy: 0.8810\n",
            "Epoch 13/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8653 - val_loss: 0.4155 - val_accuracy: 0.8824\n",
            "Epoch 14/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8591 - val_loss: 0.4035 - val_accuracy: 0.8824\n",
            "Epoch 15/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8693 - val_loss: 0.3934 - val_accuracy: 0.8889\n",
            "Epoch 16/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8594 - val_loss: 0.3840 - val_accuracy: 0.8889\n",
            "Epoch 17/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3952 - accuracy: 0.8666 - val_loss: 0.3756 - val_accuracy: 0.8954\n",
            "Epoch 18/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3776 - accuracy: 0.8853 - val_loss: 0.3682 - val_accuracy: 0.9059\n",
            "Epoch 19/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8760 - val_loss: 0.3604 - val_accuracy: 0.8954\n",
            "Epoch 20/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8787 - val_loss: 0.3541 - val_accuracy: 0.8954\n",
            "Epoch 21/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3720 - accuracy: 0.8708 - val_loss: 0.3484 - val_accuracy: 0.8954\n",
            "Epoch 22/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8907 - val_loss: 0.3432 - val_accuracy: 0.9059\n",
            "Epoch 23/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8769 - val_loss: 0.3388 - val_accuracy: 0.9059\n",
            "Epoch 24/200\n",
            "49/49 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8726 - val_loss: 0.3347 - val_accuracy: 0.9059\n",
            "Epoch 25/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8776 - val_loss: 0.3317 - val_accuracy: 0.9085\n",
            "Epoch 26/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8869 - val_loss: 0.3279 - val_accuracy: 0.9072\n",
            "Epoch 27/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8878 - val_loss: 0.3247 - val_accuracy: 0.9072\n",
            "Epoch 28/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8760 - val_loss: 0.3228 - val_accuracy: 0.9124\n",
            "Epoch 29/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8774 - val_loss: 0.3197 - val_accuracy: 0.9072\n",
            "Epoch 30/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8901 - val_loss: 0.3179 - val_accuracy: 0.9124\n",
            "Epoch 31/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8862 - val_loss: 0.3156 - val_accuracy: 0.9085\n",
            "Epoch 32/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8751 - val_loss: 0.3140 - val_accuracy: 0.9124\n",
            "Epoch 33/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8723 - val_loss: 0.3123 - val_accuracy: 0.9124\n",
            "Epoch 34/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8777 - val_loss: 0.3105 - val_accuracy: 0.9124\n",
            "Epoch 35/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.8909 - val_loss: 0.3093 - val_accuracy: 0.9150\n",
            "Epoch 36/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8875 - val_loss: 0.3085 - val_accuracy: 0.9216\n",
            "Epoch 37/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.9004 - val_loss: 0.3065 - val_accuracy: 0.9124\n",
            "Epoch 38/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8850 - val_loss: 0.3057 - val_accuracy: 0.9163\n",
            "Epoch 39/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8859 - val_loss: 0.3048 - val_accuracy: 0.9163\n",
            "Epoch 40/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8940 - val_loss: 0.3041 - val_accuracy: 0.9216\n",
            "Epoch 41/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8873 - val_loss: 0.3033 - val_accuracy: 0.9203\n",
            "Epoch 42/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8805 - val_loss: 0.3025 - val_accuracy: 0.9216\n",
            "Epoch 43/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8802 - val_loss: 0.3020 - val_accuracy: 0.9216\n",
            "Epoch 44/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8997 - val_loss: 0.3007 - val_accuracy: 0.9163\n",
            "Epoch 45/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8924 - val_loss: 0.3003 - val_accuracy: 0.9203\n",
            "Epoch 46/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8901 - val_loss: 0.2995 - val_accuracy: 0.9203\n",
            "Epoch 47/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.9009 - val_loss: 0.2989 - val_accuracy: 0.9203\n",
            "Epoch 48/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8983 - val_loss: 0.2983 - val_accuracy: 0.9203\n",
            "Epoch 49/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.9001 - val_loss: 0.2983 - val_accuracy: 0.9216\n",
            "Epoch 50/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8874 - val_loss: 0.2975 - val_accuracy: 0.9216\n",
            "Epoch 51/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8953 - val_loss: 0.2973 - val_accuracy: 0.9255\n",
            "Epoch 52/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.9061 - val_loss: 0.2964 - val_accuracy: 0.9203\n",
            "Epoch 53/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8913 - val_loss: 0.2961 - val_accuracy: 0.9216\n",
            "Epoch 54/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.9005 - val_loss: 0.2962 - val_accuracy: 0.9294\n",
            "Epoch 55/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8918 - val_loss: 0.2952 - val_accuracy: 0.9242\n",
            "Epoch 56/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.9120 - val_loss: 0.2949 - val_accuracy: 0.9255\n",
            "Epoch 57/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.9045 - val_loss: 0.2943 - val_accuracy: 0.9242\n",
            "Epoch 58/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.9252 - val_loss: 0.2939 - val_accuracy: 0.9242\n",
            "Epoch 59/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8967 - val_loss: 0.2934 - val_accuracy: 0.9242\n",
            "Epoch 60/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.9146 - val_loss: 0.2926 - val_accuracy: 0.9203\n",
            "Epoch 61/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.9056 - val_loss: 0.2927 - val_accuracy: 0.9294\n",
            "Epoch 62/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.9076 - val_loss: 0.2924 - val_accuracy: 0.9294\n",
            "Epoch 63/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.9202 - val_loss: 0.2918 - val_accuracy: 0.9255\n",
            "Epoch 64/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.9011 - val_loss: 0.2917 - val_accuracy: 0.9294\n",
            "Epoch 65/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.9083 - val_loss: 0.2906 - val_accuracy: 0.9203\n",
            "Epoch 66/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.8992 - val_loss: 0.2906 - val_accuracy: 0.9294\n",
            "Epoch 67/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.9163 - val_loss: 0.2902 - val_accuracy: 0.9294\n",
            "Epoch 68/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.9140 - val_loss: 0.2894 - val_accuracy: 0.9203\n",
            "Epoch 69/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8987 - val_loss: 0.2895 - val_accuracy: 0.9294\n",
            "Epoch 70/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.9129 - val_loss: 0.2890 - val_accuracy: 0.9294\n",
            "Epoch 71/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9159 - val_loss: 0.2890 - val_accuracy: 0.9294\n",
            "Epoch 72/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8999 - val_loss: 0.2886 - val_accuracy: 0.9294\n",
            "Epoch 73/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.9059 - val_loss: 0.2886 - val_accuracy: 0.9320\n",
            "Epoch 74/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.9165 - val_loss: 0.2878 - val_accuracy: 0.9294\n",
            "Epoch 75/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.9020 - val_loss: 0.2873 - val_accuracy: 0.9294\n",
            "Epoch 76/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.9231 - val_loss: 0.2866 - val_accuracy: 0.9229\n",
            "Epoch 77/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.9084 - val_loss: 0.2872 - val_accuracy: 0.9346\n",
            "Epoch 78/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.9229 - val_loss: 0.2864 - val_accuracy: 0.9320\n",
            "Epoch 79/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 0.9194 - val_loss: 0.2855 - val_accuracy: 0.9281\n",
            "Epoch 80/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.9132 - val_loss: 0.2859 - val_accuracy: 0.9346\n",
            "Epoch 81/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.9272 - val_loss: 0.2853 - val_accuracy: 0.9346\n",
            "Epoch 82/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.9149 - val_loss: 0.2851 - val_accuracy: 0.9346\n",
            "Epoch 83/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.9179 - val_loss: 0.2849 - val_accuracy: 0.9346\n",
            "Epoch 84/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.9090 - val_loss: 0.2840 - val_accuracy: 0.9333\n",
            "Epoch 85/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.9206 - val_loss: 0.2840 - val_accuracy: 0.9346\n",
            "Epoch 86/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.9200 - val_loss: 0.2834 - val_accuracy: 0.9346\n",
            "Epoch 87/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.9234 - val_loss: 0.2829 - val_accuracy: 0.9346\n",
            "Epoch 88/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.9120 - val_loss: 0.2822 - val_accuracy: 0.9333\n",
            "Epoch 89/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.9119 - val_loss: 0.2827 - val_accuracy: 0.9373\n",
            "Epoch 90/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.9264 - val_loss: 0.2817 - val_accuracy: 0.9346\n",
            "Epoch 91/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.9230 - val_loss: 0.2818 - val_accuracy: 0.9386\n",
            "Epoch 92/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.9168 - val_loss: 0.2815 - val_accuracy: 0.9386\n",
            "Epoch 93/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.9279 - val_loss: 0.2804 - val_accuracy: 0.9346\n",
            "Epoch 94/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.9159 - val_loss: 0.2809 - val_accuracy: 0.9386\n",
            "Epoch 95/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.9196 - val_loss: 0.2798 - val_accuracy: 0.9346\n",
            "Epoch 96/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3060 - accuracy: 0.9120 - val_loss: 0.2796 - val_accuracy: 0.9386\n",
            "Epoch 97/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.9227 - val_loss: 0.2795 - val_accuracy: 0.9399\n",
            "Epoch 98/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.9305 - val_loss: 0.2783 - val_accuracy: 0.9307\n",
            "Epoch 99/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.9138 - val_loss: 0.2787 - val_accuracy: 0.9399\n",
            "Epoch 100/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.9222 - val_loss: 0.2780 - val_accuracy: 0.9399\n",
            "Epoch 101/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.9347 - val_loss: 0.2770 - val_accuracy: 0.9307\n",
            "Epoch 102/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2946 - accuracy: 0.9108 - val_loss: 0.2772 - val_accuracy: 0.9399\n",
            "Epoch 103/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.9241 - val_loss: 0.2764 - val_accuracy: 0.9346\n",
            "Epoch 104/200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.9310 - val_loss: 0.2766 - val_accuracy: 0.9399\n",
            "Epoch 105/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.9243 - val_loss: 0.2756 - val_accuracy: 0.9359\n",
            "Epoch 106/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.9178 - val_loss: 0.2750 - val_accuracy: 0.9333\n",
            "Epoch 107/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.9168 - val_loss: 0.2748 - val_accuracy: 0.9359\n",
            "Epoch 108/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.9322 - val_loss: 0.2745 - val_accuracy: 0.9359\n",
            "Epoch 109/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.9358 - val_loss: 0.2742 - val_accuracy: 0.9373\n",
            "Epoch 110/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.9210 - val_loss: 0.2736 - val_accuracy: 0.9359\n",
            "Epoch 111/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.9288 - val_loss: 0.2734 - val_accuracy: 0.9373\n",
            "Epoch 112/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.9383 - val_loss: 0.2732 - val_accuracy: 0.9399\n",
            "Epoch 113/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.9359 - val_loss: 0.2724 - val_accuracy: 0.9373\n",
            "Epoch 114/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.9116 - val_loss: 0.2726 - val_accuracy: 0.9399\n",
            "Epoch 115/200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.9350 - val_loss: 0.2723 - val_accuracy: 0.9399\n",
            "Epoch 116/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.9201 - val_loss: 0.2712 - val_accuracy: 0.9373\n",
            "Epoch 117/200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.2691 - accuracy: 0.9308 - val_loss: 0.2704 - val_accuracy: 0.9359\n",
            "Epoch 118/200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.3247 - accuracy: 0.8983 - val_loss: 0.2715 - val_accuracy: 0.9438\n",
            "Epoch 119/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.9380 - val_loss: 0.2702 - val_accuracy: 0.9373\n",
            "Epoch 120/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.9277 - val_loss: 0.2696 - val_accuracy: 0.9373\n",
            "Epoch 121/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.9307 - val_loss: 0.2692 - val_accuracy: 0.9373\n",
            "Epoch 122/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.9194 - val_loss: 0.2689 - val_accuracy: 0.9373\n",
            "Epoch 123/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.9257 - val_loss: 0.2686 - val_accuracy: 0.9373\n",
            "Epoch 124/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.9288 - val_loss: 0.2674 - val_accuracy: 0.9373\n",
            "Epoch 125/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.9303 - val_loss: 0.2673 - val_accuracy: 0.9373\n",
            "Epoch 126/200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.9182 - val_loss: 0.2680 - val_accuracy: 0.9451\n",
            "Epoch 127/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.9395 - val_loss: 0.2670 - val_accuracy: 0.9373\n",
            "Epoch 128/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.9350 - val_loss: 0.2661 - val_accuracy: 0.9373\n",
            "Epoch 129/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.9249 - val_loss: 0.2656 - val_accuracy: 0.9373\n",
            "Epoch 130/200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.2897 - accuracy: 0.9315 - val_loss: 0.2657 - val_accuracy: 0.9386\n",
            "Epoch 131/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.9384 - val_loss: 0.2645 - val_accuracy: 0.9373\n",
            "Epoch 132/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.9338 - val_loss: 0.2646 - val_accuracy: 0.9373\n",
            "Epoch 133/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.9414 - val_loss: 0.2639 - val_accuracy: 0.9373\n",
            "Epoch 134/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.9134 - val_loss: 0.2644 - val_accuracy: 0.9451\n",
            "Epoch 135/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.9477 - val_loss: 0.2629 - val_accuracy: 0.9373\n",
            "Epoch 136/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.9287 - val_loss: 0.2628 - val_accuracy: 0.9373\n",
            "Epoch 137/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.9339 - val_loss: 0.2620 - val_accuracy: 0.9373\n",
            "Epoch 138/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.9412 - val_loss: 0.2616 - val_accuracy: 0.9373\n",
            "Epoch 139/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.9227 - val_loss: 0.2614 - val_accuracy: 0.9373\n",
            "Epoch 140/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.9267 - val_loss: 0.2629 - val_accuracy: 0.9490\n",
            "Epoch 141/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.9346 - val_loss: 0.2605 - val_accuracy: 0.9373\n",
            "Epoch 142/200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.9354 - val_loss: 0.2601 - val_accuracy: 0.9386\n",
            "Epoch 143/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.9347 - val_loss: 0.2591 - val_accuracy: 0.9359\n",
            "Epoch 144/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.9368 - val_loss: 0.2591 - val_accuracy: 0.9373\n",
            "Epoch 145/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2698 - accuracy: 0.9302 - val_loss: 0.2587 - val_accuracy: 0.9386\n",
            "Epoch 146/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2500 - accuracy: 0.9395 - val_loss: 0.2579 - val_accuracy: 0.9359\n",
            "Epoch 147/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.9193 - val_loss: 0.2576 - val_accuracy: 0.9359\n",
            "Epoch 148/200\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.9313 - val_loss: 0.2576 - val_accuracy: 0.9412\n",
            "Epoch 149/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.9386 - val_loss: 0.2569 - val_accuracy: 0.9386\n",
            "Epoch 150/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.9394 - val_loss: 0.2562 - val_accuracy: 0.9359\n",
            "Epoch 151/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.9129 - val_loss: 0.2563 - val_accuracy: 0.9412\n",
            "Epoch 152/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3157 - accuracy: 0.9245 - val_loss: 0.2561 - val_accuracy: 0.9425\n",
            "Epoch 153/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.9392 - val_loss: 0.2551 - val_accuracy: 0.9412\n",
            "Epoch 154/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.9426 - val_loss: 0.2541 - val_accuracy: 0.9359\n",
            "Epoch 155/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.9318 - val_loss: 0.2536 - val_accuracy: 0.9359\n",
            "Epoch 156/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.9292 - val_loss: 0.2539 - val_accuracy: 0.9412\n",
            "Epoch 157/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.9415 - val_loss: 0.2538 - val_accuracy: 0.9438\n",
            "Epoch 158/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.9472 - val_loss: 0.2527 - val_accuracy: 0.9399\n",
            "Epoch 159/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.9195 - val_loss: 0.2538 - val_accuracy: 0.9490\n",
            "Epoch 160/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9434 - val_loss: 0.2515 - val_accuracy: 0.9386\n",
            "Epoch 161/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.3032 - accuracy: 0.9268 - val_loss: 0.2514 - val_accuracy: 0.9412\n",
            "Epoch 162/200\n",
            "49/49 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.9201 - val_loss: 0.2513 - val_accuracy: 0.9438\n",
            "Epoch 163/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.9423 - val_loss: 0.2504 - val_accuracy: 0.9412\n",
            "Epoch 164/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.9385 - val_loss: 0.2500 - val_accuracy: 0.9412\n",
            "Epoch 165/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.9421 - val_loss: 0.2490 - val_accuracy: 0.9412\n",
            "Epoch 166/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2630 - accuracy: 0.9420 - val_loss: 0.2492 - val_accuracy: 0.9438\n",
            "Epoch 167/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.9303 - val_loss: 0.2487 - val_accuracy: 0.9425\n",
            "Epoch 168/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.9243 - val_loss: 0.2492 - val_accuracy: 0.9490\n",
            "Epoch 169/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.9406 - val_loss: 0.2473 - val_accuracy: 0.9412\n",
            "Epoch 170/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.9374 - val_loss: 0.2467 - val_accuracy: 0.9412\n",
            "Epoch 171/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.9477 - val_loss: 0.2465 - val_accuracy: 0.9425\n",
            "Epoch 172/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.9406 - val_loss: 0.2452 - val_accuracy: 0.9399\n",
            "Epoch 173/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2424 - accuracy: 0.9474 - val_loss: 0.2447 - val_accuracy: 0.9399\n",
            "Epoch 174/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.9300 - val_loss: 0.2445 - val_accuracy: 0.9412\n",
            "Epoch 175/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.9303 - val_loss: 0.2441 - val_accuracy: 0.9412\n",
            "Epoch 176/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9442 - val_loss: 0.2432 - val_accuracy: 0.9412\n",
            "Epoch 177/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.9369 - val_loss: 0.2428 - val_accuracy: 0.9412\n",
            "Epoch 178/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.9341 - val_loss: 0.2431 - val_accuracy: 0.9438\n",
            "Epoch 179/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2717 - accuracy: 0.9468 - val_loss: 0.2424 - val_accuracy: 0.9438\n",
            "Epoch 180/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9469 - val_loss: 0.2412 - val_accuracy: 0.9412\n",
            "Epoch 181/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.9288 - val_loss: 0.2410 - val_accuracy: 0.9412\n",
            "Epoch 182/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.9475 - val_loss: 0.2403 - val_accuracy: 0.9412\n",
            "Epoch 183/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.9413 - val_loss: 0.2401 - val_accuracy: 0.9425\n",
            "Epoch 184/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2361 - accuracy: 0.9556 - val_loss: 0.2391 - val_accuracy: 0.9412\n",
            "Epoch 185/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2509 - accuracy: 0.9437 - val_loss: 0.2393 - val_accuracy: 0.9451\n",
            "Epoch 186/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2394 - accuracy: 0.9545 - val_loss: 0.2374 - val_accuracy: 0.9399\n",
            "Epoch 187/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.9327 - val_loss: 0.2377 - val_accuracy: 0.9412\n",
            "Epoch 188/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.9415 - val_loss: 0.2375 - val_accuracy: 0.9451\n",
            "Epoch 189/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.9431 - val_loss: 0.2358 - val_accuracy: 0.9412\n",
            "Epoch 190/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9337 - val_loss: 0.2363 - val_accuracy: 0.9451\n",
            "Epoch 191/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9455 - val_loss: 0.2348 - val_accuracy: 0.9412\n",
            "Epoch 192/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9465 - val_loss: 0.2351 - val_accuracy: 0.9425\n",
            "Epoch 193/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.9460 - val_loss: 0.2354 - val_accuracy: 0.9477\n",
            "Epoch 194/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9415 - val_loss: 0.2344 - val_accuracy: 0.9451\n",
            "Epoch 195/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2428 - accuracy: 0.9474 - val_loss: 0.2332 - val_accuracy: 0.9412\n",
            "Epoch 196/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.9454 - val_loss: 0.2324 - val_accuracy: 0.9412\n",
            "Epoch 197/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9493 - val_loss: 0.2318 - val_accuracy: 0.9412\n",
            "Epoch 198/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.9360 - val_loss: 0.2315 - val_accuracy: 0.9412\n",
            "Epoch 199/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9332 - val_loss: 0.2319 - val_accuracy: 0.9477\n",
            "Epoch 200/200\n",
            "49/49 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.9392 - val_loss: 0.2306 - val_accuracy: 0.9425\n",
            "49/49 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.9426\n",
            "Train score: [0.24687685072422028, 0.942617654800415]\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.9425\n",
            "Test score: [0.2305615246295929, 0.94248366355896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "31yp5KCd7TKA",
        "outputId": "0cf02b29-008d-4d8e-e925-f64f9bde4c39"
      },
      "source": [
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc69fd32050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "g5tdSqRp7TKB",
        "outputId": "776ec5c1-2839-4096-b25e-8026909072ed"
      },
      "source": [
        "# Plot the accuracy too\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc69fbb0250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AhT3fRI7TKE",
        "outputId": "c6edaeac-d672-4808-fdd6-e4f6a3bbcc15"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 1)                 15        \n",
            "=================================================================\n",
            "Total params: 15\n",
            "Trainable params: 15\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuqLpsSI7TKF",
        "outputId": "33097a46-c7ca-4b40-d231-67f7fee6564f"
      },
      "source": [
        "for z in zip(df_wide.columns.values,model.layers[0].get_weights()[0]):\n",
        "  print(z)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('BLUETOOTH_DEVICES', array([1.5769815], dtype=float32))\n",
            "('GPS_FIX_SATELLITES', array([-0.5805946], dtype=float32))\n",
            "('GPS_SATELLITES', array([-1.3195285], dtype=float32))\n",
            "('TMD3725_Light Ambient Light Sensor Non-wakeup', array([-1.757152], dtype=float32))\n",
            "('TMD3725_Proximity Proximity Sensor Wakeup', array([0.2236675], dtype=float32))\n",
            "('WIFI_ACCESS_POINTS', array([2.7982395], dtype=float32))\n",
            "('IN_VEHICLE', array([-0.42295727], dtype=float32))\n",
            "('ON_BICYCLE', array([-0.02433211], dtype=float32))\n",
            "('ON_FOOT', array([-2.6682303], dtype=float32))\n",
            "('STILL', array([1.1899261], dtype=float32))\n",
            "('UNKOWN', array([0.13014506], dtype=float32))\n",
            "('TILTING', array([-0.1099721], dtype=float32))\n",
            "('WALKING', array([0.30828434], dtype=float32))\n",
            "('RUNNING', array([0.6284711], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}